# Artifact for the TACAS Submission 'Cyclone: A Heterogeneous Tool for Checking Infinite Descent'

## Docker Image

Assuming you have Docker installed and defaultly configured on your machine, run the following command to pull the artifact Docker image and to start a container with the image:

```bash
docker pull matanshaked/cyclone_artifact
docker run -it matanshaked/cyclone_artifact
```

The files in the docker image are split into the following directory tree:

```
/
├── home
    ├── README.md
    ├── cyclist/
    ├── scripts/
        ├── generate_database.sh
        ├── graph_stats.sh
        ├── evaluate_cyclone.sh
    ├── paper_data/
        ├── stats.csv
        ├── evaluation.csv
        ├── database/
```

The current file is `README.md`.

## *Cyclone* Implementation

The `cyclist` directory contains the source code for Cyclist together with the integration of our implementation of *Cyclone*.

The code of our implementation can be found in the `cyclist/src/generic` subdirectory, with the most relevant files being `cyclone.c`, `criterion.flat_cycles.c`, `criterion.descending_unicycles.c` and `criterion.trace_manifold.c`.

This code mirrors the contents of the `TACAS2025` tag of the [Cyclist github repository](https://github.com/cyclist-org/cyclist/releases/tag/TACAS2025).

## The Data used in our Paper

The `paper_data` directory contains:

* The sloped graphs database from our paper, in a `database` subdirectory.
* The `stats.csv` file that we used in our paper (as described in the [graph stats](#graph_statssh) section).
* The `evaluation.csv` file that we used in our paper (as described in the [evaluate cyclone](#evaluate_cyclonesh) section).

## Reproducing our Results

Follow the instructions above to run the Docker image.

The `scripts` directory contains scripts for generating all of the data that we used in our paper and our results.

### `generate_database.sh`

This script generates a database of sloped graphs, storing it in the directory `/home/database` which contains two directories, one for each logic: `fo` and `sl`.
Each of these directories contains `.json` files, one for each sloped graph that was generated.

This script can take several minutes.

Note that because Cyclist times out while searching for a proof for some of the test cases in the test suite, the amount of graphs in the database can differ slightly from the amount that we report in the paper.
However, the proof search and naming scheme for the sloped graph files is deterministic.
This means that any file generated by the script with the same name as a file contained in the `paper_data/database` directory will contain the same sloped graph representation.

### `graph_stats.sh`

This script generates a CSV file, `/home/stats.csv`, containing the following statistics for each sloped graph in the database:

* The sloped graph filename,
* The metrics described in section 3 in the paper,
* The runtime and the answer of each incomplete method,
* Other information described in the CSV header.

This script should be run after the [`generate_database.sh`](#generate_databasesh) script, as it uses the generated sloped graphs.

### `evaluate_cyclone.sh`

This script creates a CSV file, `/home/evaluation.csv`, containing the runtime evaluation of *Cyclone*.
The following information is given for each sloped graph in the database.

* The name of the file containing the sloped graph,
* The runtimes of each complete method presented in the paper,
* The number of edges.

This script should be run after both the [`generate_database.sh`](#generate_databasesh) and the[`graph_stats.sh`](#graph_statssh) scripts, as it uses the sloped graphs in the database and some of their calculated metrics.

This script might take a few hours, mainly because it is running the very slow SLA method.
It is possible to add `-method <method name>` flags, with `<method name>` being one of the following: `VLA`, `SLA`, `FWK`, `OR`, indicating which methods to run in the evaluation.
Note that by default all methods run and if any `-method` flag is passed, only the flagged methods run.
